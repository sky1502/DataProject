{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8099b5cd-dec0-44c5-9736-ce3c086f121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b4e9c6-d37a-4c9b-b00a-9e292e1261c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = 'data/Arrival_Departure/Bus_Arr_Dep_2018/MBTA Bus Arrival Departure Oct-Dec 2018.csv'\n",
    "# df = pd.read_csv(d)\n",
    "# # df = df.rename(columns={\n",
    "# #     'ServiceDate': 'service_date',\n",
    "# #     'Route': 'route_id',\n",
    "# #     'Direction': 'direction_id',\n",
    "# #     'HalfTripId': 'half_trip_id',\n",
    "# #     'Stop': 'stop_id',\n",
    "# #     'Timepoint': 'time_point_id',\n",
    "# #     'TimepointOrder': 'time_point_order',\n",
    "# #     'PointType': 'point_type',\n",
    "# #     'StandardType': 'standard_type',\n",
    "# #     'Scheduled': 'scheduled',\n",
    "# #     'Actual': 'actual',\n",
    "# #     'ScheduledHeadway': 'scheduled_headway',\n",
    "# #     'Headway': 'headway'\n",
    "# # })\n",
    "# df = df.rename(columns={'direction': 'direction_id'})\n",
    "# df = df.drop('earliness', axis = 1)\n",
    "# df.to_csv('data/Arrival_Departure/Bus_Arr_Dep_2018/MBTA Bus Arrival Departure Oct-Dec 2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb0a34b-305a-4402-9ca2-d4cec550e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = 'data/Arrival_Departure/Bus_Arr_Dep_2024/100k.csv'\n",
    "# d2 = 'data/Arrival_Departure/Bus_Arr_Dep_2024/MBTA-Bus-Arrival-Departure-Times_2024-07.csv'\n",
    "# df1 = pd.read_csv(d1)[0:5]\n",
    "# df2 = pd.read_csv(d2)[0:5]\n",
    "# # df2 = df2.rename(columns={'direction': 'direction_id'})\n",
    "# l1 = list(df1.columns)\n",
    "# l2 = list(df2.columns)\n",
    "# print(l1)\n",
    "# print(l2)\n",
    "# # df = df[0:99999]\n",
    "# # print(df1.dtypes)\n",
    "# # print(df2.dtypes)\n",
    "\n",
    "# are_equal = (l1 == l2)\n",
    "# print(\"Do list1 and list2 have the same elements?\", are_equal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "915e2b27-0e2a-4297-88c0-9ce483155954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = 'data/Arrival_Departure/Post_Covid/Bus_Arr_Dep_2024/MBTA-Bus-Arrival-Departure-Times_2024-12.csv'\n",
    "# df = pd.read_csv(d)\n",
    "# print(df.head())\n",
    "\n",
    "# df['service_date'] = df['service_date'].astype(str)\n",
    "# df['scheduled'] = df['scheduled'].astype(str)\n",
    "# df['actual'] = df['actual'].astype(str)\n",
    "# print(\"x2\")\n",
    "\n",
    "# # mask_service = df['service_date'].str.contains('T') & df['service_date'].str.endswith('Z')\n",
    "# # df.loc[mask_service, 'service_date'] = df.loc[mask_service, 'service_date'].str.replace(r'T.*Z$', '', regex=True)\n",
    "# mask_service = df['service_date'].str.contains(' ')\n",
    "# df.loc[mask_service, 'service_date'] = df.loc[mask_service, 'service_date'].str.replace(r'\\s.*', '', regex=True)\n",
    "# print(\"x3\")\n",
    "\n",
    "# for col in ['scheduled', 'actual']:\n",
    "#     mask = df[col].str.contains('T') & df[col].str.endswith('Z')\n",
    "#     df.loc[mask, col] = df.loc[mask, col].str.replace('T', ' ', regex=False).str.replace('Z', '', regex=False)\n",
    "# print(\"x4\")\n",
    "\n",
    "# df['service_date'] = pd.to_datetime(df['service_date'], format='%Y-%m-%d', errors='coerce')\n",
    "# df['scheduled'] = pd.to_datetime(df['scheduled'], errors='coerce')\n",
    "# df['actual'] = pd.to_datetime(df['actual'], errors='coerce')\n",
    "\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3e4b5cdf-c210-4c34-bab9-abf0dbba1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b911ea0c-3528-4cda-9e1d-649d34e6342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(d, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "348f50d9-be16-49e8-9fa3-85dd57804e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_directory = 'data/Arrival_Departure/Post_Covid/Bus_Arr_Dep_2024'\n",
    "\n",
    "# combined_df = []\n",
    "\n",
    "# # Walk through all the folders and subfolders in the root directory\n",
    "# for foldername, subfolders, filenames in os.walk(root_directory):\n",
    "#     for filename in filenames:\n",
    "#         # Check if the file is a CSV\n",
    "#         if filename.endswith('.csv'):\n",
    "#             # Construct the full file path (including subfolders)\n",
    "#             file_path = os.path.join(foldername, filename)\n",
    "            \n",
    "#             # Read the CSV file into a DataFrame\n",
    "#             df = pd.read_csv(file_path)\n",
    "            \n",
    "#             # Append the DataFrame to the list\n",
    "#             combined_df.append(df)\n",
    "\n",
    "# # Concatenate all DataFrames into one\n",
    "# final_df = pd.concat(combined_df, ignore_index=True)\n",
    "\n",
    "# # Save the combined DataFrame to a new CSV file\n",
    "# final_df.to_csv('data/Arrival_Departure/arr_dep_2024.csv', index=False)\n",
    "\n",
    "# print(\"CSV files combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "70e3bec8-b3ed-4f66-99ca-4e5bb7b2e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined successfully!\n"
     ]
    }
   ],
   "source": [
    "root_directory = 'data/Arrival_Departure/Working/Covid'\n",
    "\n",
    "combined_df = []\n",
    "\n",
    "# Walk through all the folders and subfolders in the root directory\n",
    "for foldername, subfolders, filenames in os.walk(root_directory):\n",
    "    for filename in filenames:\n",
    "        # Check if the file is a CSV\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct the full file path (including subfolders)\n",
    "            file_path = os.path.join(foldername, filename)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            combined_df.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(combined_df, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "final_df.to_csv('data/Arrival_Departure/Working/covid.csv', index=False)\n",
    "\n",
    "print(\"CSV files combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d2fa10-4ebf-40ac-a309-f1c667e26ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_date          object\n",
      "route_id              object\n",
      "direction_id          object\n",
      "half_trip_id         float64\n",
      "stop_id              float64\n",
      "time_point_id         object\n",
      "time_point_order     float64\n",
      "point_type            object\n",
      "standard_type         object\n",
      "scheduled             object\n",
      "actual                object\n",
      "scheduled_headway    float64\n",
      "headway              float64\n",
      "dtype: object\n",
      "service_date          object\n",
      "route_id              object\n",
      "direction_id          object\n",
      "half_trip_id         float64\n",
      "stop_id              float64\n",
      "time_point_id         object\n",
      "time_point_order     float64\n",
      "point_type            object\n",
      "standard_type         object\n",
      "scheduled             object\n",
      "actual                object\n",
      "scheduled_headway    float64\n",
      "headway              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "d = 'data/Arrival_Departure/Working/covid.csv'\n",
    "df = pd.read_csv(d)\n",
    "print(df.dtypes)\n",
    "df['direction_id'] = df['direction_id'].astype(str)\n",
    "df['time_point_id'] = df['time_point_id'].astype(str)\n",
    "df['route_id'] = df['route_id'].astype(str)\n",
    "df['point_type'] = df['point_type'].astype(str)\n",
    "df['standard_type'] = df['standard_type'].astype(str)\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d498a6bf-f064-4525-92e7-ae3dc5e1cf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates:\n",
      "82197836\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "invalid_dates = df[df['service_date'].isna()]\n",
    "print(\"Invalid dates:\")\n",
    "print(len(df))\n",
    "print(len(invalid_dates))\n",
    "\n",
    "# # Found only 7 rows in covid.csv with null values in service_date column\n",
    "# df = df.dropna(subset=['service_date'])\n",
    "# invalid_dates = df[df['service_date'].isna()]\n",
    "# print(\"Invalid dates:\")\n",
    "# print(len(df))\n",
    "# print(len(invalid_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f76b44-ce65-44df-b390-9f82bea66880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Arrival_Departure/Working/covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088a91-9a61-4dc2-9428-bd36488b7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scheduled'] = pd.to_datetime(data['scheduled'], errors='coerce')\n",
    "data['actual'] = pd.to_datetime(data['actual'], errors='coerce')\n",
    "\n",
    "# Calculate delay (difference between actual and scheduled departure times)\n",
    "data['delay'] = (data['actual'] - data['scheduled']).dt.total_seconds()\n",
    "\n",
    "# Calculate the wait time for each trip (difference between actual departure and previous scheduled departure)\n",
    "# First, sort the data by route_id and service_date to ensure the time order is correct\n",
    "data = data.sort_values(by=['route_id', 'service_date', 'half_trip_id', 'time_point_order'])\n",
    "\n",
    "# Create a column for the previous trip's scheduled time\n",
    "data['previous_scheduled'] = data.groupby(['route_id', 'service_date', 'half_trip_id'])['scheduled'].shift(1)\n",
    "\n",
    "# Calculate wait time as the difference between the current trip's actual time and the previous trip's scheduled time\n",
    "data['wait_time'] = (data['actual'] - data['previous_scheduled']).dt.total_seconds()\n",
    "\n",
    "# For trips without a previous trip, set wait time as NaN\n",
    "data['wait_time'] = data['wait_time'].fillna(0)\n",
    "\n",
    "# Check the data after preprocessing\n",
    "data[['service_date', 'route_id', 'scheduled', 'actual', 'delay', 'wait_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9949f-24d7-4d5a-b9e5-5b400cc8573a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
